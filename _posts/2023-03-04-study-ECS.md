---
title: "ECS(Entity Component System)"
date: 2023-04-11T15:00:00
categories: 
  - study
tags: 
  - graphics
image: 
  thumbnail: /images/s_0-ANIMATION.gif
---
 
# Theory
ECS 란 한마디로 data-oriented framework라고 할 수 있다. Vulkan API 공부를 하다가 알게됐는데, 예전에 Unity에서도 다뤄봤던 개념이었다. 

그때는 뭔지 모르고 단순히 구조를 따라가서 사용하기만 했었는데 왜 이런 구조를 사용하는지 알게되니 꽤 재미있는 내용이란 생각이 들었다. 

관련해서 간단하지만 원리를 잘 설명해주는 블로그 글을 보게 됐는데, 그 practice를 직접 따라 해보는 과정을 남기려고 한다. 

- [https://austinmorlan.com/posts/entity_component_system/](https://austinmorlan.com/posts/entity_component_system/)
- 인상적인 내용만 요약해보려 한다.

## ECS란?
전통적으로 게임개발에서 OOP(Object Oriented Programming)의 패러다임으로 접근을 많이 했다고 한다. 예를 들어 
```
actor ─┬─ human   ─── shop-keeper
       └─ monster ─── goblin
```
과 같이 class와 상속 관계를 정의하고 각 object의 instance에서 .render()를 호출하는 방식의 OOP구현이 있다고 해보자.

여기에는 두가지 문제가 있다고 한다.
- 문제점
  - 유연성
    - 만약에 고블린이 인간과 친해져서 경비원을 하고 싶다고 해보자. 상속 관계가 복잡해지는 문제가 있다.
  - cache 사용성
    - 예를들어 물리 시스템에서 각 객체가 좌표, 속도, 가속도의 데이터를 가진다고 가정해보자.
    - 각 객체가 모든 데이터를 다 포함하고 있는 OOP 구조에서는 객체1의 좌표에 접근할때 cache line을 따라서 객체1의 속도나 가속도 데이터의 접근에 캐시 사용의 이득을 볼 수 있을 것이다. 그러나 다른 객체들 (객체2~1000)의 정보들에는 이런 이득을 보지 못하게 된다면 캐시 사용을 충분히 하지 못하게 된다.
    - 이 문제가 과거에 메인 메모리에서 cpu 로 데이터를 불러들이는 과정이 오래걸리던 시대에는 bottle-neck이었다고 한다. 현대에도 이처럼 게임 구현의 디자인 차원에서 cpu optimization을 고려해야할 만큼 중요도가 높은지에 대해서는 논란의 여지가 있는 것 같으나, 이미 많은 게임엔진 등에서 사용되는 기법이고 장단점을 알고 가는 것에서 의미를 두기로 했다.

- 해결
  - component 기반 접근
    - Unity에서 사용하는 방법이기도 하다.
    - object에 여러 component를 추가/제거하기가 용이하다.
  - pack tightly 
    - component들을 POD(Plain Old Data)로 정의한다.
    - 그리고 여러 객체를 iterate할때, 필요한 component를 가지고 있는 객체들만 돌면, 필요한 데이터만 cache로 불러들여서 locality를 충분히 활용할 수 있게 된다.
- 요약
  - Entity란 그냥 단순한 ID다.
  - Component는 특정 객체가 가질 특성들만 모아놓은 것이다. (Transform, RigidBody, Gravity, Renderable 등등). Entity가 각 특성의 struct에 index로 사용된다.
  - System은 이 component들에 작동하는 로직이다.

이외의 구현 디테일은 원본 글에 자세히 설명되어 있다.

## cache 개념 Recap

학생때 Computer Architecture 수업을 들었는데, 별로 흥미를 못느꼈던 기억이 있다. 교수님이 굉장히 로봇같이 수업 진도를 나가주셨던 기억과 과제로 verilog를 사용해서 CPU 기능들을 구현했던 것이 기억이나는데, 이왕 건드린 김에 복습 겸 정리를 해놓으려 한다.

### 캐시 계층
캐시는 단순하게 말해서 메인메모리(DRAM)의 데이터 접근이 느리기 때문에, 자주 쓰이는 값을 미리 빠른 장치에 저장해 놓는 메모리다.
이런 메모리 구조는 따지고 보면 컴퓨터의 모든 메모리 계층 구조에 쓰이는 원리인데, 빠른 접근을 할 수 있는 메모리는 그 용량이 작다 (그리고 비싸다.)
대략 레지스터-캐시-메인메모리-하드디스크(혹은 SSD) 같은 구조이고, 캐시 역시 계층을 두어 L1, L2, L3 캐시를 둔다.
Hit와 Miss 두 상황에 대해서, hit이면 해당 계층에서 바로 데이터를 가져와서 쓸 수 있는 것이고, Miss인 경우 다음 계층의 메모리를 참조하게 되는 계층적 구조이다.

### 캐시의 종류
제일 먼저 Direct-mapped cache를 설명해보겠다.
메인 메모리가 M=2^m bytes, 캐시를 C=2^c bytes라고 해보자. 보통 접근하는 데이터 크기가 4, 8 byte 등으로 묶여져 있으니 G=2^g로 granularity를 두자.

그럼 m-bit 의 메모리 주소값을 3 부분으로 나누자. t / c-g / g. 즉 t = m-c이다. 이 중 c-g를 cache의 index로 사용하고, t는 tag bank에 저장하여 중복될 수 밖에 없는 다른 주소들에 대해 확인할 때 쓰인다. 여기에 valid bit까지 필요하니까 t+1 bits에 대한 저장공간에 추가로 들게 된다. 이를 줄이기 위해서 여러 G-bytes를 묶어서 하나의 block으로 다루면(offset을 확인할 bit도 생각해야함.), Direct-Mapped cache의 형태가 된다.
block size B=2^b bytes라고 하면, m-bit는 t/c-b/b/g로 구성되고, C/B개의 t bits로 이루어진 태그 뱅크, 1bit Valid, C/B개의 B bytes로 이루어진 데이터 뱅크가 캐시의 구조가 된다.

이때 tag + valid + data를 합친 하나의 bank가 cache를 이루게 되는데, 이 bank를 여러개 (a개) 두면 a-way set-associative cache가 된다. 하나의 cache index에 대해서 a개의 중복된 뱅크를 두어 conflict를 줄이는 방식이다. a개의 bank의 tag bank는 각각 C/B/a개의 t bits로 이뤄졌다.

즉 associativity란, 메인메모리의 특정 entry(주소) 가 cache의 어떤 부분으로 mapping 될지에 대한 정책인데, 아무데나 갈수 있으면 fully associative, 위치가 정해져 있으면 direct-mapped, a-군데로 갈 수 있으면 a-way set associative라고 한다. 여기에 최대로 가능한 a는 몇일까? C/B이다. 즉 모든 index에 entry가 저장될 수 있고 탐색해야 하는 상황이다. 이런 형태를 fully-associative라고 한다.

trade-off는 check해야할 bank가 많아질수록 더 많은 power와 chip area가 필요하고 latency가 증가하게 된다.

miss의 종류
- cold
  - 처음 불러올때 필연적으로 발생하는 miss다.
  - B가 design factor이고 데이터 locality와 관련이 있다.
- capacity
  - 그냥 cache의 용량이 작아서 발생할 수 밖에 없는 miss. C와 관련있다.
- conflict
  - a와 관련있고, set의 way가 부족할 때 발생한다. fully-associated cache에소는 발생하지 않았을 miss라면 여기에 해당한다.
- coherence
  - 멀티코어에서 상위 캐시를 코어마다 가지고 하위 캐시는 공유하는 구조에서 발생가능한 문제.

### 캐시에 Write
캐시에 접근한다는 것은 read/write 두가지가 있다. 이 중 write의 경우는 데이터를 변경하는 것이기 때문에 계층구조와 일관성 등을 고려해야해서 여러 정책을 나눌 수 있다.
- hit 인 경우
  -  write-through
     -  L1에 hit인 경우 L2도 업데이트 해주는 방식.
  -  write-back
     -  L1만 업데이트 하고 dirty로 표시해놓고 나중에 하위 계층에 업데이트 해주는 방식.
- miss
  - write-alloc
    - L1에서 write miss인 경우 그 block을 L1에 할당해주는 방식. 
  - write-no-alloc
    - L1에서 write miss인 경우 L1할당은 안하고 하위 계층에만 그 block을 할당하는 방식. 할당은 read-miss일때만 일어남.
- 주로 쓰는 조합
  - wb & wa
    - locality가 큰 경우 이점을 볼 수 있음
  - wt & wna
    - 같은 entry에 연속 write할때 이점이 딱히 없음.

### Instruction and Data 

- Harvard architecture
  - instruction과 data를 별도의 starage로 두는 구조
- Princeton architecture
  - 폰노이만의 unified 구조
주로 L1 캐시를 split으로 쓰고 L2, L3를 unified로 씀.  
L1 cache를 split하면 free doubled bandwidth 효과를 볼 수 있어서.



# Practice
## step-0
## step-1
## step-2
## step-3
## step-4

<image src="/images/s_0-ANIMATION.gif" alt="img" width="900" /> 
